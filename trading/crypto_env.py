import numpy as np
import gymnasium as gym
from gymnasium import spaces
from data.fear_and_greed import FearGreedIndexFetcher
from trading.crypto_env_utils import precompute_model_predictions, calculate_reward, get_observation


class CryptoTradingEnv(gym.Env):
    def __init__(self, symbol, data, df_original_dict, sentiment_scores, lstm_models, np_models,
                 xgb_model, xgb_scaler_X, xgb_scaler_y, observation_scaler,
                 initial_balance=1000, trading_fee=0.1, sl_multiplier=2, tp_multiplier=3):

        super().__init__()

        self.symbol = symbol
        self.data = data
        self.df_original_dict = df_original_dict
        self.sentiment_scores = sentiment_scores
        self.lstm_models = lstm_models
        self.np_models = np_models
        self.xgb_model = xgb_model
        self.scaler_X = xgb_scaler_X
        self.scaler_y = xgb_scaler_y
        self.observation_scaler = observation_scaler
        self.initial_balance = initial_balance
        self.balance = initial_balance
        self.trading_fee = trading_fee
        self.sl_multiplier = sl_multiplier
        self.tp_multiplier = tp_multiplier
        self.consecutive_profitable_trades = 0
        self.pyramid_count = 0
        self.feature_names = [
            'close', 'rsi', 'ema', 'adx', 'atr', 'volume',
            'cci', 'williams_r', 'momentum', 'mfi', 'mass_index'
        ]

        self.position = None
        self.position_price = None
        self.position_open_step = None
        self.current_step = 20
        self.pnl = 0.0

        obs_len = data.shape[1]  # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –±–µ—Ä—ë–º –∏–∑ shape –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ state_data
        self.action_space = spaces.Discrete(3)
        self.observation_space = spaces.Box(low=-1, high=1, shape=(obs_len,), dtype=np.float32)

    def adapt_strategy_parameters(self):
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
        adx = self.data[self.current_step, self.feature_names.index('adx')]
        atr = self.data[self.current_step, self.feature_names.index('atr')]
        sentiment = self.sentiment_scores[self.current_step]

        # –ò–Ω–¥–µ–∫—Å —Å—Ç—Ä–∞—Ö–∞ –∏ –∂–∞–¥–Ω–æ—Å—Ç–∏
        fg_index, _ = FearGreedIndexFetcher.fetch_current_index()
        fg_scaled = fg_index / 100 if fg_index else 0.5

        # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∞–Ω—Ç–∏–º–µ–Ω—Ç–∞
        if sentiment > 0.2:
            self.trade_bias = 'long'
        elif sentiment < -0.2:
            self.trade_bias = 'short'
        else:
            self.trade_bias = 'neutral'

        # –ê–¥–∞–ø—Ç–∞—Ü–∏—è —Ä–∏—Å–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω–¥–µ–∫—Å–∞ —Å—Ç—Ä–∞—Ö–∞ –∏ –∂–∞–¥–Ω–æ—Å—Ç–∏
        self.risk_multiplier = 1 + (fg_scaled - 0.5)

        # –ê–¥–∞–ø—Ç–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ TP –∏ SL –Ω–∞ –æ—Å–Ω–æ–≤–µ ATR –∏ ADX
        if adx > 50:
            self.dynamic_take_profit = atr * 3.0
            self.dynamic_stop_loss = atr * 1.5
        elif adx > 30:
            self.dynamic_take_profit = atr * 2.5
            self.dynamic_stop_loss = atr * 1.25
        else:
            self.dynamic_take_profit = atr * 2.0
            self.dynamic_stop_loss = atr

        # –ê–¥–∞–ø—Ç–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ –ø–æ–∑–∏—Ü–∏–∏
        base_risk = 0.01
        self.position_size = (base_risk * self.balance * self.risk_multiplier)

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ —Ä–∏—Å–∫—É –∏ —Ä–∞–∑–º–µ—Ä—É –ø–æ–∑–∏—Ü–∏–∏
        self.position_size = np.clip(self.position_size, self.balance * 0.005, self.balance * 0.05)

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)

        min_step = 20
        max_step = len(self.data) - 150

        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏ –≤—ã–±–∏—Ä–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é —Ç–æ—á–∫—É
        if max_step > min_step:
            self.current_step = np.random.randint(min_step, max_step)
        else:
            # –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ, –±–µ—Ä—ë–º –±–µ–∑–æ–ø–∞—Å–Ω—É—é —Ç–æ—á–∫—É
            self.current_step = min_step if len(self.data) > min_step else 0

        self.balance = self.initial_balance
        self.position = None
        self.position_price = None
        self.position_open_step = None
        self.pnl = 0.0
        self.consecutive_profitable_trades = 0
        self.pyramid_count = 0
        precompute_model_predictions(self)
        self.adapt_strategy_parameters()

        return self._get_observation(), {}

    def step(self, action):
        # üëá –∞–¥–∞–ø—Ç–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        self.adapt_strategy_parameters()

        current_price, atr, adx = (
            self.data[self.current_step][0],
            self.data[self.current_step][-1],
            self.data[self.current_step][-2]
        )

        reward = calculate_reward(self, action, current_price, atr, adx)

        self.current_step += 1
        terminated = self.current_step >= len(self.data) - 1
        obs = self._get_observation()

        return obs, reward, terminated, False, {}

    def _get_observation(self):
        obs = get_observation(self)
        if np.isnan(obs).any() or np.isinf(obs).any():
            print(f"üö® NaN –∏–ª–∏ Inf –≤ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è—Ö –Ω–∞ —à–∞–≥–µ {self.current_step}. –ó–∞–º–µ–Ω—è—é –Ω–∞ –Ω—É–ª–∏.")
            obs = np.nan_to_num(obs, nan=0.0, posinf=0.0, neginf=0.0)
        return obs

    def check_observations(self):
        print("üîç –ó–∞–ø—É—Å–∫–∞—é –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞–±–ª—é–¥–µ–Ω–∏–π...")

        for step in range(20, len(self.data) - 150):
            self.current_step = step
            obs = self._get_observation()
            if np.isnan(obs).any() or np.isinf(obs).any():
                print(f"üö® –û—à–∏–±–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —à–∞–≥–µ {step}: –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN –∏–ª–∏ Inf!")
                return False

        print("‚úÖ –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–π–¥–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        return True

    def render(self):
        print(f"Step: {self.current_step}, Balance: {self.balance:.2f}, Position: {self.position}, PNL: {self.pnl:.2f}")
